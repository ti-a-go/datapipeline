services:
  pyspark:
    build: 
      context: .
      args:
        - JDBC_POSTGRES_DRIVER_FOLDER=${JDBC_POSTGRES_DRIVER_FOLDER}
        - JDBC_POSTGRES_DRIVER_VERSION=${JDBC_POSTGRES_DRIVER_VERSION}
    container_name: pyspark
    volumes:
      - ./:/usr/app
    profiles:
      - spark
  
  source-database:
    image: postgres:17.4-alpine
    container_name: source-db
    environment:
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_DB: ${DATABASE_NAME}
    volumes:
      - source_pgdata:/var/lib/postgresql/data
      - ./scripts/source:/docker-entrypoint-initdb.d
      - ./data/source:/usr/data
    ports:
      - "5432:5432"
    profiles:
      - db
    
  target-database:
    image: postgres:17.4-alpine
    container_name: target-db
    environment:
      POSTGRES_USER: ${TARGET_DATABASE_USER}
      POSTGRES_PASSWORD: ${TARGET_DATABASE_PASSWORD}
      POSTGRES_DB: ${TARGET_DATABASE_NAME}
    volumes:
      - target_pgdata:/var/lib/postgresql/data
      - ./scripts/target:/docker-entrypoint-initdb.d
      - ./data/target:/usr/data
    ports:
      - "5434:5432"
    profiles:
      - db

  test:
    build:
      context: .
      target: test
    container_name: test
    volumes:
      - ./:/usr/app
    profiles:
      - test
  
  preload:
    build:
      context: .
      target: preload
    container_name: preload
    volumes:
      - ./:/usr/app
    profiles:
      - preload

volumes:
  source_pgdata:
  target_pgdata: